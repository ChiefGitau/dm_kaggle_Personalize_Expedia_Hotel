{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:30:20.098549Z",
     "start_time": "2025-05-18T20:30:20.081141Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Main Experiment Notebook for Expedia Hotel Booking Prediction\n",
    "\n",
    "Assignment 2: Data Mining Techniques, Vrije Universiteit Amsterdam\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb # Keep for type hints if needed, but direct use will be less\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import os\n",
    "\n",
    "# Import the modularized model functions\n",
    "import lightgbm_ranker_model as lgbm_model\n",
    "import warnings # For managing warnings from Optuna/LightGBM if needed\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "# Point to our feature-engineered dataset\n",
    "TRAIN_FILE = 'imputed_sample_data_with_features.csv'\n",
    "# Check if feature-engineered dataset exists and use it if available\n",
    "if os.path.exists(TRAIN_FILE):\n",
    "    print(f\"Using feature-engineered dataset: {TRAIN_FILE}\")\n",
    "else:\n",
    "    # Fallback to original file\n",
    "    TRAIN_FILE = os.path.join(DATA_DIR, 'train_imputed.csv')\n",
    "    print(f\"Feature-engineered dataset not found. Using: {TRAIN_FILE}\")\n",
    "\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'test.csv') # Defined TEST_FILE path\n",
    "SUBMISSION_FILENAME = 'submission_feature_engin.csv' # Updated submission filename\n",
    "\n",
    "SAMPLE_FRACTION = 0.1 # Use 10% of the data for faster runs during development\n",
    "N_FOLDS_CV = 5         # Number of folds for general cross-validation\n",
    "N_FOLDS_TUNING = 3     # Number of folds for Optuna trials (can be smaller for speed)\n",
    "N_OPTUNA_TRIALS = 20   # Number of Optuna trials\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading training data...\")\n",
    "try:\n",
    "    df_train_full = pd.read_csv(TRAIN_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Training file not found at {TRAIN_FILE}\")\n",
    "    df_train_full = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    df_train_full = None\n",
    "\n",
    "# df_sample = TRAIN_FILE"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using feature-engineered dataset: imputed_sample_data_with_features.csv\n",
      "Loading training data...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:30:20.177436Z",
     "start_time": "2025-05-18T20:30:20.128508Z"
    }
   },
   "source": "# --- 4. Initial Feature Selection & Preparation ---\nX = None\ny = None\ngroups_for_splitting = None # This will be df_sample['srch_id'] for GroupKFold.split\nfeature_columns = [] # Initialize\n\nif df_sample is not None:\n    print(\"\\nDefining feature set and preparing X, y, groups...\")\n    \n    # Basic features from original dataset\n    basic_features = [\n        'visitor_location_country_id', 'prop_country_id',\n        'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n        'prop_location_score1', 'prop_location_score2', 'prop_log_historical_price',\n        'price_usd', 'promotion_flag', 'orig_destination_distance'\n    ]\n    \n    # Time-based features from feature engineering\n    time_features = [\n        'year', 'month', 'day', 'dayofweek', 'hour', 'season', 'is_weekend', \n        'day_part', 'days_since_first_date', 'checkin_month', 'checkin_dayofweek', \n        'checkin_season', 'is_holiday_season'\n    ]\n    \n    # User-based features from feature engineering\n    user_features = [\n        'has_user_history', 'star_rating_match', 'price_match', 'is_domestic_search',\n        'total_travelers', 'has_children', 'is_family', 'rooms_per_person',\n        'is_short_stay', 'is_long_stay', 'is_last_minute', 'is_early_booking',\n        'price_vs_country_avg', 'stay_vs_country_avg'\n    ]\n    \n    # Property-based features from feature engineering\n    property_features = [\n        'hotel_quality', 'star_review_gap', 'combined_location_score', \n        'location_quality', 'distance_category', 'prop_popularity', \n        'prop_country_rank', 'prop_country_rank_pct', 'prop_matches_destination'\n    ]\n    \n    # Price and value features from feature engineering\n    price_features = [\n        'price_per_person', 'price_per_night', 'price_per_room',\n        'value_for_money', 'value_for_money_normalized', 'price_normalized',\n        'price_rank', 'price_rank_pct', 'price_tier', 'price_zscore',\n        'has_promotion', 'log_price_ratio', 'price_discount'\n    ]\n    \n    # Competitive position features from feature engineering\n    comp_features = [\n        'comp_rate_available', 'comp_inv_available', 'competitors_count',\n        'better_price_count', 'worse_price_count', 'price_comp_ratio',\n        'avg_price_diff', 'comp_advantage'\n    ]\n    \n    # Interaction features from feature engineering\n    interaction_features = [\n        'user_prop_country_match', 'star_rating_for_price', 'review_for_price',\n        'location_for_price', 'family_friendly_score', 'business_travel_score',\n        'vacation_score', 'quality_price_ratio'\n    ]\n    \n    # PCA components (if available)\n    pca_features = [f'pca_component_{i+1}' for i in range(20)]\n    \n    # Combine all feature groups (start with basic features, then add others if available)\n    all_feature_groups = [\n        (\"Basic\", basic_features),\n        (\"Time\", time_features),\n        (\"User\", user_features),\n        (\"Property\", property_features),\n        (\"Price\", price_features),\n        (\"Competitive\", comp_features),\n        (\"Interaction\", interaction_features),\n        (\"PCA\", pca_features)\n    ]\n    \n    # Find which features are actually available in our dataset\n    feature_columns = []\n    for group_name, group_features in all_feature_groups:\n        available_features = [col for col in group_features if col in df_sample.columns]\n        feature_columns.extend(available_features)\n        if available_features:\n            print(f\"✓ Added {len(available_features)}/{len(group_features)} {group_name} features\")\n        else:\n            print(f\"✗ No {group_name} features found in dataset\")\n            \n    # Remove duplicate features if any\n    feature_columns = list(dict.fromkeys(feature_columns))\n    \n    if not feature_columns:\n        print(\"Error: No feature columns selected or available. Stopping.\")\n    else:\n        X = df_sample[feature_columns].copy()\n        y = df_sample['relevance'].copy()\n        groups_for_splitting = df_sample['srch_id'] # Used by GroupKFold for splitting\n\n        # Basic Imputation for any remaining missing values\n        print(\"Performing basic median imputation for numerical features in X...\")\n        for col in X.columns:\n            if X[col].isnull().any():\n                if pd.api.types.is_numeric_dtype(X[col]):\n                    median_val = X[col].median()\n                    X[col].fillna(median_val, inplace=True)\n                    # print(f\"Imputed NaNs in '{col}' with median: {median_val}\")\n                # Add mode imputation for categorical if any, or use a placeholder string\n        \n        print(f\"Selected {len(feature_columns)} features total\")\n        print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n        print(f\"NaNs remaining in X after imputation: {X.isnull().sum().sum()}\")\n        if groups_for_splitting is not None:\n            print(f\"Number of unique groups for splitting: {groups_for_splitting.nunique()}\")\nelse:\n    print(\"Skipping feature selection as df_sample is None.\")\n\n# Display X's head to verify\nif X is not None:\n    display(X.head(3))",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m groups_for_splitting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;66;03m# This will be df_sample['srch_id'] for GroupKFold.split\u001B[39;00m\n\u001B[1;32m      5\u001B[0m feature_columns \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;66;03m# Initialize\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdf_sample\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDefining feature set and preparing X, y, groups...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Basic features from original dataset\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_sample' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing 5-Fold Cross-Validation using modular function ---\n",
      "\\n--- Performing 5-Fold Cross-Validation ---\n",
      "--- Fold 1/5 ---\n",
      "Fold 1 NDCG@5: 0.3428\n",
      "--- Fold 2/5 ---\n",
      "Fold 2 NDCG@5: 0.3423\n",
      "--- Fold 3/5 ---\n",
      "Fold 3 NDCG@5: 0.3455\n",
      "--- Fold 4/5 ---\n",
      "Fold 4 NDCG@5: 0.3530\n",
      "--- Fold 5/5 ---\n",
      "Fold 5 NDCG@5: 0.3536\n",
      "Mean NDCG@5 across 5 folds: 0.3475 +/- 0.0049\n",
      "\n",
      "Cross-Validation Mean NDCG@5: 0.3475 +/- 0.0049\n",
      "\n",
      "Average Feature Importances from CV:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feature\n",
       "prop_location_score2           15831.198095\n",
       "price_usd                      11461.798124\n",
       "prop_location_score1            7153.288665\n",
       "prop_starrating                 5405.245977\n",
       "prop_log_historical_price       5379.496554\n",
       "prop_review_score               2834.064519\n",
       "promotion_flag                  2247.297013\n",
       "orig_destination_distance       1730.336422\n",
       "prop_country_id                 1018.822620\n",
       "visitor_location_country_id      507.976540\n",
       "prop_brand_bool                  428.788319\n",
       "Name: importance, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 5. Cross-Validation (using modular function) ---\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Found \\'eval_at\\' in params.*')\n",
    "mean_cv_ndcg = 0\n",
    "std_cv_ndcg = 0\n",
    "cv_feature_importances = pd.Series(dtype=float) # Initialize as an empty Series\n",
    "\n",
    "if X is not None and y is not None and groups_for_splitting is not None and df_sample is not None:\n",
    "    # Basic LGBM params for initial CV\n",
    "    # These will be merged with/override defaults in the perform_cross_validation function\n",
    "    initial_lgbm_params = {\n",
    "        'n_estimators': 100, # Example: function's default might be different\n",
    "        'learning_rate': 0.1, # Example\n",
    "        'random_state': RANDOM_STATE\n",
    "        # The modular function defines other necessary defaults like objective, metric, label_gain, eval_at etc.\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- Performing {N_FOLDS_CV}-Fold Cross-Validation using modular function ---\")\n",
    "    mean_cv_ndcg, std_cv_ndcg, cv_feature_importances = lgbm_model.perform_cross_validation(\n",
    "        X, y, \n",
    "        groups_for_splitting=groups_for_splitting, # This is df_sample['srch_id']\n",
    "        df_full_for_group_counts=df_sample, # Pass df_sample, as it contains 'srch_id' needed for group counts\n",
    "        n_folds=N_FOLDS_CV,\n",
    "        lgbm_params=initial_lgbm_params\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCross-Validation Mean NDCG@5: {mean_cv_ndcg:.4f} +/- {std_cv_ndcg:.4f}\")\n",
    "    if not cv_feature_importances.empty:\n",
    "        print(\"\\nAverage Feature Importances from CV:\")\n",
    "        with pd.option_context('display.max_rows', 30): # Display top 20 or all if less than 20\n",
    "            display(cv_feature_importances.head(20))\n",
    "else:\n",
    "    print(\"\\nSkipping Cross-Validation due to missing X, y, groups_for_splitting, or df_sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 15:11:15,776] A new study created in memory with name: lgbm_ranker_tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Hyperparameters with Optuna (20 trials, 3 CV folds each) using modular function ---\n",
      "\\n--- Tuning Hyperparameters with Optuna (20 trials, 3 CV folds each) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 15:11:19,215] Trial 0 finished with value: 0.3483959691013827 and parameters: {'n_estimators': 350, 'learning_rate': 0.10148640916203272, 'num_leaves': 26, 'max_depth': 12, 'min_child_samples': 6, 'subsample': 0.5604481619303492, 'colsample_bytree': 0.7128952769140711, 'reg_alpha': 5.632050975812048, 'reg_lambda': 0.01393055140628837}. Best is trial 0 with value: 0.3483959691013827.\n",
      "[I 2025-05-14 15:11:22,750] Trial 1 finished with value: 0.3487982556281389 and parameters: {'n_estimators': 700, 'learning_rate': 0.07738743799224009, 'num_leaves': 50, 'max_depth': 8, 'min_child_samples': 30, 'subsample': 0.6195409659098858, 'colsample_bytree': 0.9036249138323806, 'reg_alpha': 7.446041659683735, 'reg_lambda': 6.2495614061886355}. Best is trial 1 with value: 0.3487982556281389.\n",
      "[I 2025-05-14 15:11:24,863] Trial 2 finished with value: 0.35174829820481407 and parameters: {'n_estimators': 400, 'learning_rate': 0.1734440198649952, 'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 58, 'subsample': 0.994009316145284, 'colsample_bytree': 0.7229225094690845, 'reg_alpha': 0.002544358343653164, 'reg_lambda': 0.1930789012781852}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:27,550] Trial 3 finished with value: 0.3444268791354786 and parameters: {'n_estimators': 700, 'learning_rate': 0.048487561299753845, 'num_leaves': 31, 'max_depth': 12, 'min_child_samples': 61, 'subsample': 0.5188748007776129, 'colsample_bytree': 0.8970206485636432, 'reg_alpha': 2.3691588622455257, 'reg_lambda': 1.2654777765757108}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:30,274] Trial 4 finished with value: 0.3354143619650662 and parameters: {'n_estimators': 600, 'learning_rate': 0.1519837982748114, 'num_leaves': 103, 'max_depth': 12, 'min_child_samples': 73, 'subsample': 0.6551003922424845, 'colsample_bytree': 0.5916291042615215, 'reg_alpha': 0.6750851601772996, 'reg_lambda': 0.018937668512042222}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:32,655] Trial 5 finished with value: 0.3458824661214159 and parameters: {'n_estimators': 150, 'learning_rate': 0.04752011450715754, 'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 81, 'subsample': 0.6114376813883363, 'colsample_bytree': 0.8639411728449384, 'reg_alpha': 1.1358835087291093, 'reg_lambda': 0.0011821749270259797}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:35,443] Trial 6 finished with value: 0.335001575572149 and parameters: {'n_estimators': 100, 'learning_rate': 0.13049478057898115, 'num_leaves': 121, 'max_depth': 8, 'min_child_samples': 33, 'subsample': 0.7017967493102486, 'colsample_bytree': 0.7708521939849334, 'reg_alpha': 0.001018306399097641, 'reg_lambda': 0.13489391247397012}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:38,100] Trial 7 finished with value: 0.34362440215036366 and parameters: {'n_estimators': 200, 'learning_rate': 0.03268816446547107, 'num_leaves': 79, 'max_depth': 6, 'min_child_samples': 78, 'subsample': 0.9946455105737699, 'colsample_bytree': 0.8106489362165528, 'reg_alpha': 0.0010833647706765762, 'reg_lambda': 0.006844506750138019}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:39,493] Trial 8 finished with value: 0.33508241592841775 and parameters: {'n_estimators': 450, 'learning_rate': 0.01811125891212415, 'num_leaves': 85, 'max_depth': 3, 'min_child_samples': 9, 'subsample': 0.8523469965366194, 'colsample_bytree': 0.7370293883755854, 'reg_alpha': 1.5117893548494583, 'reg_lambda': 0.007620996501664811}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:41,359] Trial 9 finished with value: 0.3466650358242032 and parameters: {'n_estimators': 550, 'learning_rate': 0.09049688789687663, 'num_leaves': 130, 'max_depth': 3, 'min_child_samples': 19, 'subsample': 0.9439161838484604, 'colsample_bytree': 0.5316873806840319, 'reg_alpha': 2.1981254082152226, 'reg_lambda': 3.086369792229482}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:44,525] Trial 10 finished with value: 0.33905585153938095 and parameters: {'n_estimators': 300, 'learning_rate': 0.010404350542921773, 'num_leaves': 59, 'max_depth': 5, 'min_child_samples': 99, 'subsample': 0.8334839813499626, 'colsample_bytree': 0.995303594578808, 'reg_alpha': 0.022451539482305733, 'reg_lambda': 0.3234171141198142}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:47,319] Trial 11 finished with value: 0.34415990248628003 and parameters: {'n_estimators': 450, 'learning_rate': 0.18647449756091486, 'num_leaves': 54, 'max_depth': 9, 'min_child_samples': 41, 'subsample': 0.7978184305269341, 'colsample_bytree': 0.6586238368426612, 'reg_alpha': 0.045909965650061293, 'reg_lambda': 8.184046048299765}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:50,589] Trial 12 finished with value: 0.3438220985734841 and parameters: {'n_estimators': 550, 'learning_rate': 0.06384336264081673, 'num_leaves': 57, 'max_depth': 6, 'min_child_samples': 48, 'subsample': 0.7518016518295703, 'colsample_bytree': 0.9684698047952724, 'reg_alpha': 0.008914755539095355, 'reg_lambda': 0.6254579384253999}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:53,088] Trial 13 finished with value: 0.3419578691728356 and parameters: {'n_estimators': 700, 'learning_rate': 0.08076941553129545, 'num_leaves': 47, 'max_depth': 10, 'min_child_samples': 28, 'subsample': 0.8868954181653865, 'colsample_bytree': 0.6506124957391568, 'reg_alpha': 0.18012989958463674, 'reg_lambda': 0.07018880903867619}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:56,434] Trial 14 finished with value: 0.34647328602833927 and parameters: {'n_estimators': 250, 'learning_rate': 0.028964002311892487, 'num_leaves': 69, 'max_depth': 5, 'min_child_samples': 58, 'subsample': 0.6769958887341323, 'colsample_bytree': 0.8846020681752738, 'reg_alpha': 0.17116049415121967, 'reg_lambda': 4.921870260187403}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:11:58,904] Trial 15 finished with value: 0.34660598408048143 and parameters: {'n_estimators': 400, 'learning_rate': 0.11633518958804226, 'num_leaves': 39, 'max_depth': 10, 'min_child_samples': 43, 'subsample': 0.6027155439348006, 'colsample_bytree': 0.8079119133765934, 'reg_alpha': 0.003919327580051043, 'reg_lambda': 1.5941627170463581}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:12:03,065] Trial 16 finished with value: 0.3406229403882976 and parameters: {'n_estimators': 600, 'learning_rate': 0.17623824371839195, 'num_leaves': 146, 'max_depth': 7, 'min_child_samples': 24, 'subsample': 0.763483966050713, 'colsample_bytree': 0.9383930439396932, 'reg_alpha': 9.16963999098815, 'reg_lambda': 0.06892047179344488}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:12:05,511] Trial 17 finished with value: 0.3483133994900416 and parameters: {'n_estimators': 500, 'learning_rate': 0.06701697257749081, 'num_leaves': 22, 'max_depth': 5, 'min_child_samples': 65, 'subsample': 0.9426753464983313, 'colsample_bytree': 0.6788679480647025, 'reg_alpha': 0.38748523103320637, 'reg_lambda': 0.3019796937274395}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:12:08,375] Trial 18 finished with value: 0.34100238193015925 and parameters: {'n_estimators': 350, 'learning_rate': 0.03161122760104547, 'num_leaves': 102, 'max_depth': 4, 'min_child_samples': 36, 'subsample': 0.5141088206231738, 'colsample_bytree': 0.7921666231144328, 'reg_alpha': 0.05053661340176915, 'reg_lambda': 0.0021491028926194818}. Best is trial 2 with value: 0.35174829820481407.\n",
      "[I 2025-05-14 15:12:11,796] Trial 19 finished with value: 0.3403809351977362 and parameters: {'n_estimators': 300, 'learning_rate': 0.19945578181896698, 'num_leaves': 68, 'max_depth': 7, 'min_child_samples': 51, 'subsample': 0.7134205521477647, 'colsample_bytree': 0.8418259219149622, 'reg_alpha': 0.004277146050865765, 'reg_lambda': 1.9070453292383973}. Best is trial 2 with value: 0.35174829820481407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna study finished. Best trial NDCG@5: 0.3517\n",
      "Best parameters: {'n_estimators': 400, 'learning_rate': 0.1734440198649952, 'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 58, 'subsample': 0.994009316145284, 'colsample_bytree': 0.7229225094690845, 'reg_alpha': 0.002544358343653164, 'reg_lambda': 0.1930789012781852}\n",
      "\n",
      "Best parameters found by Optuna:\n",
      "    n_estimators: 400\n",
      "    learning_rate: 0.1734440198649952\n",
      "    num_leaves: 36\n",
      "    max_depth: 4\n",
      "    min_child_samples: 58\n",
      "    subsample: 0.994009316145284\n",
      "    colsample_bytree: 0.7229225094690845\n",
      "    reg_alpha: 0.002544358343653164\n",
      "    reg_lambda: 0.1930789012781852\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Hyperparameter Tuning with Optuna (using modular function) ---\n",
    "best_params_from_tuning = {} # Initialize\n",
    "\n",
    "if X is not None and y is not None and groups_for_splitting is not None and df_sample is not None:\n",
    "    print(f\"\\n--- Tuning Hyperparameters with Optuna ({N_OPTUNA_TRIALS} trials, {N_FOLDS_TUNING} CV folds each) using modular function ---\")\n",
    "    \n",
    "    # Suppress Optuna's verbosity if it's too much, and LightGBM warnings during tuning.\n",
    "    # import optuna # Optuna is imported within lgbm_model.py where tune_hyperparameters_optuna is defined.\n",
    "    # optuna.logging.set_verbosity(optuna.logging.WARNING) # You can set this in lgbm_model.py if desired globally for the function\n",
    "    \n",
    "    # It's good practice to manage warnings that might clutter the output during tuning.\n",
    "    # The lgbm_model.py file could also handle these internally if preferred.\n",
    "    warnings.filterwarnings('ignore', message='Found \\'eval_at\\' in params.*') # Suppress LightGBM's specific warning\n",
    "    warnings.filterwarnings('ignore', message='Overriding the init_model argument.*') # Another potential LightGBM warning\n",
    "\n",
    "    best_params_from_tuning = lgbm_model.tune_hyperparameters_optuna(\n",
    "        X, \n",
    "        y, \n",
    "        groups_for_splitting=groups_for_splitting, # This is df_sample['srch_id']\n",
    "        df_full_for_group_counts=df_sample, # df_sample for calculating group sizes within folds\n",
    "        n_trials=N_OPTUNA_TRIALS, \n",
    "        n_cv_folds=N_FOLDS_TUNING\n",
    "    )\n",
    "    \n",
    "    if best_params_from_tuning:\n",
    "        print(\"\\nBest parameters found by Optuna:\")\n",
    "        for key, value in best_params_from_tuning.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        print(\"\\nOptuna tuning did not return parameters. Using default parameters for the final model evaluation.\")\n",
    "        # Fallback to some sensible defaults if tuning fails or is skipped\n",
    "        best_params_from_tuning = { \n",
    "            'n_estimators': 200, 'learning_rate': 0.05, 'num_leaves': 31, \n",
    "            'max_depth': 7, 'min_child_samples': 20, 'subsample': 0.8,\n",
    "            'colsample_bytree':0.8, 'reg_alpha':0.1, 'reg_lambda':0.1\n",
    "            # Add other necessary LGBM parameters if not covered by the module's defaults\n",
    "        } \n",
    "else:\n",
    "    print(\"\\nSkipping Hyperparameter Tuning due to missing X, y, groups_for_splitting, or df_sample.\")\n",
    "    # Fallback parameters if tuning is skipped\n",
    "    best_params_from_tuning = { \n",
    "        'n_estimators': 200, 'learning_rate': 0.05, 'num_leaves': 31, \n",
    "        'max_depth': 7, 'min_child_samples': 20, 'subsample': 0.8,\n",
    "        'colsample_bytree':0.8, 'reg_alpha':0.1, 'reg_lambda':0.1\n",
    "    }\n",
    "\n",
    "# Reset warnings to default behavior if they were changed\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Training Final Model with Best Tuned Parameters ---\n",
      "\\n--- Training Final Model ---\n",
      "Final model parameters for training:\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'label_gain': [0, 1, 5], 'eval_at': [5], 'importance_type': 'gain', 'random_state': 42, 'n_jobs': -1, 'verbosity': -1, 'n_estimators': 400, 'learning_rate': 0.1734440198649952, 'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 58, 'subsample': 0.994009316145284, 'colsample_bytree': 0.7229225094690845, 'reg_alpha': 0.002544358343653164, 'reg_lambda': 0.1930789012781852}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/DM2/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final model with early stopping on 90/10 split of training data.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/DM2/lib/python3.13/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's ndcg@5: 0.363617\n",
      "Final model training completed.\n",
      "Final model successfully trained.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Train Final Model on Full Sampled Data (using modular function) ---\n",
    "final_trained_model = None\n",
    "\n",
    "if X is not None and y is not None and groups_for_splitting is not None and df_sample is not None and best_params_from_tuning:\n",
    "    print(\"\\\\n--- Training Final Model with Best Tuned Parameters ---\")\n",
    "    \n",
    "    # groups_train_full is needed for the lgbm_model.train_final_model function\n",
    "    # It should represent the group sizes for the entire X, y that's being passed\n",
    "    # This X is df_sample[feature_columns]\n",
    "    groups_train_full = df_sample.groupby('srch_id').size().to_numpy()\n",
    "\n",
    "    if len(groups_train_full) > 0:\n",
    "        final_trained_model = lgbm_model.train_final_model(\n",
    "            X_train_full=X,  # This is the full X from df_sample\n",
    "            y_train_full=y,  # This is the full y from df_sample\n",
    "            groups_train_full=groups_train_full,\n",
    "            df_full_for_group_counts=df_sample, # df_sample contains 'srch_id' for early stopping split\n",
    "            best_params=best_params_from_tuning\n",
    "        )\n",
    "        if final_trained_model:\n",
    "            print(\"Final model successfully trained.\")\n",
    "        else:\n",
    "            print(\"Final model training failed or returned None.\")\n",
    "    else:\n",
    "        print(\"Cannot train final model: No groups found in the training data.\")\n",
    "else:\n",
    "    print(\"\\\\nSkipping final model training due to missing data, groups, or best_params_from_tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Preparing Test Data and Generating Kaggle Submission ---\n",
      "Loading test data from: ../data.nosync/test.csv...\n",
      "Loaded test dataset with shape: (4959183, 50)\n",
      "\\nPreprocessing test data...\n",
      "Imputing missing values in test data using training set medians...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/ww14kyzx7zq1bdp4kybt0_800000gn/T/ipykernel_87350/802724624.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(train_median, inplace=True)\n",
      "/opt/miniconda3/envs/DM2/lib/python3.13/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs remaining in X_test after imputation: 0\n",
      "\\n--- Predicting on Test Data and Formatting Submission ---\n",
      "Submission file 'submission_modular.csv' created. Top 5 rows:\n",
      "   SearchId  PropertyId\n",
      "0         1       54937\n",
      "1         1       99484\n",
      "2         1       61934\n",
      "3         1       24194\n",
      "4         1       28181\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Prepare Test Data and Generate Kaggle Submission (using modular function) ---\n",
    "\n",
    "if final_trained_model is not None and X is not None and 'feature_columns' in locals() and feature_columns:\n",
    "    print(\"\\\\n--- Preparing Test Data and Generating Kaggle Submission ---\")\n",
    "\n",
    "    # --- 8a. Load Test Data ---\n",
    "    print(f\"Loading test data from: {TEST_FILE}...\")\n",
    "    try:\n",
    "        df_test_raw = pd.read_csv(TEST_FILE)\n",
    "        print(f\"Loaded test dataset with shape: {df_test_raw.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Test file not found at {TEST_FILE}\")\n",
    "        df_test_raw = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data: {e}\")\n",
    "        df_test_raw = None\n",
    "\n",
    "    if df_test_raw is not None:\n",
    "        # --- 8b. Preprocess Test Data ---\n",
    "        print(\"\\\\nPreprocessing test data...\")\n",
    "        \n",
    "        # Ensure all selected feature columns exist in df_test_raw\n",
    "        # and handle any missing columns gracefully if necessary (e.g. by creating them with NaNs)\n",
    "        X_test_list = []\n",
    "        for col in feature_columns:\n",
    "            if col not in df_test_raw.columns:\n",
    "                print(f\"Warning: Feature column '{col}' not found in test data. Creating it with NaNs.\")\n",
    "                df_test_raw[col] = np.nan \n",
    "        \n",
    "        X_test = df_test_raw[feature_columns].copy()\n",
    "\n",
    "        # Impute missing values in X_test using medians from the TRAINING sample (X)\n",
    "        # X should be the dataframe of features used for training the final_trained_model\n",
    "        print(\"Imputing missing values in test data using training set medians...\")\n",
    "        nan_counts_before_imputation = X_test.isnull().sum()\n",
    "\n",
    "        for col in X_test.columns:\n",
    "            if X_test[col].isnull().any():\n",
    "                if pd.api.types.is_numeric_dtype(X_test[col]):\n",
    "                    if col in X.columns: # Ensure the column exists in the training features X\n",
    "                        train_median = X[col].median() # Calculate median from the TRAIN features (X)\n",
    "                        X_test[col].fillna(train_median, inplace=True)\n",
    "                        # print(f\"Imputed NaNs in test column '{col}' with training median: {train_median}\")\n",
    "                    else:\n",
    "                        print(f\"Warning: Column '{col}' for median imputation not found in training X. Test NaNs may remain.\")\n",
    "                # else: # For categorical, use mode from training X\n",
    "                    # if col in X.columns:\n",
    "                    #     train_mode = X[col].mode()[0]\n",
    "                    #     X_test[col].fillna(train_mode, inplace=True)\n",
    "                    # else:\n",
    "                    #     print(f\"Warning: Column '{col}' for mode imputation not found in training X. Test NaNs may remain.\")\n",
    "        \n",
    "        nan_counts_after_imputation = X_test.isnull().sum().sum()\n",
    "        print(f\"NaNs remaining in X_test after imputation: {nan_counts_after_imputation}\")\n",
    "        if nan_counts_after_imputation > 0:\n",
    "            print(\"Warning: Some NaNs remain in test features after imputation. Review missing columns or imputation logic.\")\n",
    "            print(X_test.isnull().sum()[X_test.isnull().sum() > 0])\n",
    "\n",
    "\n",
    "        # --- 8c. Generate Submission File ---\n",
    "        # The df_test_raw contains 'srch_id' and 'prop_id' needed by the submission function\n",
    "        lgbm_model.predict_and_format_submission(\n",
    "            model=final_trained_model,\n",
    "            X_test=X_test,\n",
    "            df_test_original_ids=df_test_raw, # Pass the raw test df for srch_id and prop_id\n",
    "            submission_filename=SUBMISSION_FILENAME\n",
    "        )\n",
    "    else:\n",
    "        print(\"Skipping submission generation as test data could not be loaded.\")\n",
    "else:\n",
    "    print(\"\\\\nSkipping Kaggle submission: final_trained_model, X, or feature_columns not available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
